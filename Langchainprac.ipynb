{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2eb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#create an environment variable with the particular key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ba4a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ac9d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.9-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (1.4.22)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
      "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.26 (from langchain)\n",
      "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
      "  Downloading langsmith-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (1.20.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (2.5.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from langchain) (2.26.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio<5,>=3 (from langchain-core<0.2,>=0.1.26->langchain)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.26->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n",
      "  Downloading orjson-3.9.15-cp39-none-win_amd64.whl.metadata (50 kB)\n",
      "     -------------------------------------- 50.7/50.7 kB 518.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain)\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
      "   ---------------------------------------- 817.0/817.0 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 1.7/1.7 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
      "   -------------------------------------- 246.4/246.4 kB 944.6 kB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.8-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 62.2/62.2 kB 824.1 kB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 49.4/49.4 kB 834.2 kB/s eta 0:00:00\n",
      "Downloading orjson-3.9.15-cp39-none-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 135.9/135.9 kB 2.0 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typing-inspect, tenacity, packaging, orjson, jsonpointer, exceptiongroup, marshmallow, jsonpatch, anyio, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.0\n",
      "    Uninstalling packaging-21.0:\n",
      "      Successfully uninstalled packaging-21.0\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 2.2.0\n",
      "    Uninstalling anyio-2.2.0:\n",
      "      Successfully uninstalled anyio-2.2.0\n",
      "Successfully installed anyio-4.3.0 dataclasses-json-0.6.4 exceptiongroup-1.2.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.26 langsmith-0.1.8 marshmallow-3.20.2 orjson-3.9.15 packaging-23.2 tenacity-8.2.3 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0306cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openaiNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\bm\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\bm\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2021.10.8)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\bm\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 75.6/75.6 kB 135.0 kB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 77.8/77.8 kB 196.5 kB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.12.0\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7cf4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI   #imported the openai class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3752b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"Saffron Spice Bistro\"\n"
     ]
    }
   ],
   "source": [
    "#create your openai model\n",
    "\n",
    "llm=OpenAI(temperature=0.6) #how creative you want your model to be\n",
    "\n",
    "\n",
    "name=llm(\"I want to open a restaurant for Indian food. Suggest a fancy name for that.\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dafc3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a prompt template\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cca584c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name= PromptTemplate(\n",
    "input_variables=['cuisine'],\n",
    "template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acf3cbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Mexican food. Suggest a fancy name for that.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_name.format(cuisine='Mexican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chains object in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connects the llms to the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bc4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#internally this calls the openai api\n",
    "#if you use huggingface then we would use hugging face setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac95cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "571d58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "307f5a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Zaytouna Bistro\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"Lebanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfca7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential chains\n",
    "\n",
    "#input_variable= \"indian\"--> prompt(generate a restaurant name)-->restaurant_name=tandoor bites\n",
    "\n",
    "# --->give me food menu(the second chain)-->final output paneer tikka, samosa etc\n",
    "\n",
    "\n",
    "#simple sequential chain \n",
    "\"\"\"input of  second step is the output of the first step\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ea7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplesequntialchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fcdd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "input_variables=['cuisine'],\n",
    "template=\"I wan to open a restaurant for {cuisine} food. Suggest a fancy name for this.\")\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items=PromptTemplate(\n",
    "input_variables=['restaurant_name'],\n",
    "template=\"\"\"suggest some menu items for {restaurant_name}. Return it as a comma separated list\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "food_items_chain=LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9341ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Tacos al pastor\\n2. Carne asada burrito\\n3. Pollo con mole\\n4. Enchiladas suizas\\n5. Quesadillas de hongos (mushroom quesadillas)\\n6. Ceviche de camarón (shrimp ceviche)\\n7. Chiles rellenos\\n8. Sopa de tortilla (tortilla soup)\\n9. Fajitas de pollo o carne\\n10. Tamales de pollo o carne\\n11. Arroz con camarones (shrimp rice)\\n12. Tostadas de tinga (shredded chicken tostadas)\\n13. Camarones al ajillo (garlic shrimp)\\n14. Flautas de res (beef flautas)\\n15. Chilaquiles verdes (green chilaquiles)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain=SimpleSequentialChain(chains=[name_chain, food_items_chain])\n",
    "chain.run(\"mexican\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate output that is the restraunt name does not appear\n",
    "\n",
    "#however sequential chain can have multiple inputs and multiple outputs\n",
    "\n",
    "#we can customise the chains as such to give multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f620be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name=PromptTemplate(\n",
    "input_variables=['cuisine'],\n",
    "template=\"I wan to open a restaurant for {cuisine} food. Suggest a fancy name for this.\")\n",
    "\n",
    "name_chain=LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "prompt_template_items=PromptTemplate(\n",
    "input_variables=['restaurant_name'],\n",
    "template=\"\"\"suggest some menu items for {restaurant_name}. Return it as a comma separated list\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "food_items_chain=LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "491781d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bm\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Chinese',\n",
       " 'restaurant_name': '\\n\\n\"Imperial Dragon Palace\"',\n",
       " 'menu_items': \"\\n\\n1. General Tso's Chicken\\n2. Kung Pao Shrimp\\n3. Mongolian Beef\\n4. Sweet and Sour Pork\\n5. Vegetable Lo Mein\\n6. Szechuan Tofu\\n7. Egg Rolls\\n8. Hot and Sour Soup\\n9. Peking Duck\\n10. Shrimp Fried Rice\\n11. Orange Chicken\\n12. Beef and Broccoli\\n13. Crab Rangoon\\n14. Sesame Chicken\\n15. Fried Wontons\\n16. Moo Shu Pork\\n17. Vegetable Spring Rolls\\n18. Honey Walnut Shrimp\\n19. Chicken Chow Mein\\n20. Ma Po Tofu.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "#sequentialchain is more generic than simple sequential chain\n",
    "\n",
    "chain=SequentialChain(\n",
    "    chains=[name_chain, food_items_chain],\n",
    "    input_variables=['cuisine'],\n",
    "    output_variables=['restaurant_name','menu_items']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "chain({'cuisine':'Chinese'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473caf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#see sequential chains in restaurant name generator in C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a254ede9",
   "metadata": {},
   "source": [
    "## Agents in langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0fab5",
   "metadata": {},
   "source": [
    "gpt 4 take exxpedia plugins now it will be able to tell you about flights on a specific\n",
    "date \n",
    "otherwise it will not tell\n",
    "\n",
    "it will go to expedia plugin and pull those flights on specific date and destination and source\n",
    "\n",
    "\n",
    "Knowledge of gpt is limited to september 2021\n",
    "\n",
    "LLMs have both a reasoning engine and a knowledge base limited to septemeber 2021\n",
    "\n",
    "based on your query the reasoning engine will call the expedia plugin for flight enquiry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f12d5",
   "metadata": {},
   "source": [
    "Question : when was elon musk born? what is his age in 2023? (remember knowledge is limited to sept 2021)\n",
    "\n",
    "\n",
    "when was elon musk born? ---knowledge fetched from wikipedia tool: 1971\n",
    "\n",
    "age in 2023--- 2023-1971: math tool\n",
    "\n",
    "agents connect with external tool, use llms reasoning capabilities to perform a given task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb556d72",
   "metadata": {},
   "source": [
    "google search tool, math tool , wikipedia tool are available as part of langchain and you can configure your agent\n",
    "\n",
    "agent= reasoning capability+ tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aa039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fa8979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from wikipedia) (4.10.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from wikipedia) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.2.1)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11696 sha256=1e2cdf5aca8064291512ee8094cd3014ac1e9d80b67e17a6118043f119eacd70\n",
      "  Stored in directory: c:\\users\\bm\\appdata\\local\\pip\\cache\\wheels\\c2\\46\\f4\\caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962d4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.6)\n",
    "tools= load_tools([\"wikipedia\",\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8491c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tools,\n",
    "                      llm,\n",
    "                      agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67e1889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use wikipedia to find information about Elon Musk's birthdate and age\n",
      "Action: wikipedia\n",
      "Action Input: Elon Musk\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk (; EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect, and former chairman of Tesla, Inc.; owner, executive chairman, and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is one of the wealthiest people in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionaires Index, and $182.6 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and, that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal.\n",
      "In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial intelligence company.\n",
      "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and antisemitic conspiracy theories. His ownership of Twitter has been similarly controversial, being marked by the laying off of a large number of employees, an increase in hate speech and misinformation and disinformation on the website, as well as changes to Twitter Blue verification. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
      "\n",
      "Page: Twitter under Elon Musk\n",
      "Summary: Elon Musk completed his acquisition of Twitter in October 2022; Musk acted as CEO of Twitter until June 2023 when he was succeeded by Linda Yaccarino. Twitter was then rebranded to X in July 2023. Initially during Musk's tenure, Twitter introduced a series of reforms and management changes; the company reinstated a number of previously banned accounts, reduced the workforce by approximately 80%, closed one of Twitter's three data centers, and largely eliminated the content moderation team, replacing it with the crowd-sourced fact-checking system Community Notes.\n",
      "In November 2022, Twitter then began offering paid verification checkmarks, followed by removing legacy verification. In December, the Twitter Files were released and a number of journalists suspended from the platform. Th\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to find Elon Musk's age in 2023\n",
      "Action: Calculator\n",
      "Action Input: 2023 - 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know that Elon Musk will be 52 years old in 2023\n",
      "Final Answer: Elon Musk will be 52 years old in 2023\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk will be 52 years old in 2023'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"When was Elon Musk born? And what is his age in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a816c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serpAPI or google search api\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"]=\"62f8ae10fc588ee82b1c2fbe5ce6408136a970feed0a2452c9aa2e8bc04c480e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89dfadfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-resultsNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\bm\\anaconda3\\lib\\site-packages (from google-search-results) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests->google-search-results) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bm\\anaconda3\\lib\\site-packages (from requests->google-search-results) (3.2)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py): started\n",
      "  Building wheel for google-search-results (setup.py): finished with status 'done'\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32017 sha256=54ddb9acbb6ec4d0ebb11abdcb87a20dab0390feb035d4ecdf3adf45397542b1\n",
      "  Stored in directory: c:\\users\\bm\\appdata\\local\\pip\\cache\\wheels\\68\\8e\\73\\744b7d9d7ac618849d93081a20e1c0deccd2aef90901c9f5a9\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeeed363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a calculator to solve this equation.\n",
      "Action: Calculator\n",
      "Action Input: 22 + 5\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 27\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now have the answer for the year 2022.\n",
      "Action: Search\n",
      "Action Input: \"GDP of US 2022\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m$25.46 trillion\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The GDP of US in 2022 plus 5 is $25.46 trillion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GDP of US in 2022 plus 5 is $25.46 trillion.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THE tools will give the agent access to \n",
    "\n",
    "llm= OpenAI(temperature=0.6)\n",
    "\n",
    "tools= load_tools([\"serpapi\", \"llm-math\"], llm=llm) #serpapi is the google search api\n",
    "\n",
    "agent=initialize_agent(tools, llm,\n",
    "                      agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose= True)\n",
    "\n",
    "\n",
    "agent.run(\"What was the GDP of US in 2022 plus 5?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a105d0d8",
   "metadata": {},
   "source": [
    "# MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5708d2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chains do not have memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed93e3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bc6acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f703e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e426f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Spice Symphony\" '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "chain.run(\"indian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc52a6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Lebanese'), AIMessage(content='\\n\"Zaytouna Lounge\"'), HumanMessage(content='indian'), AIMessage(content='\\n\\n\"Spice Symphony\" ')]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ca1d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Lebanese\n",
      "AI: \n",
      "\"Zaytouna Lounge\"\n",
      "Human: indian\n",
      "AI: \n",
      "\n",
      "\"Spice Symphony\" \n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a80c3a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo=ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21feb5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first hockey world cup was held in 1971 and was won by the Soviet Union. The Soviet Union won all five of the first hockey world cups, until the tournament was renamed to the Ice Hockey World Championships in 1993. Since then, Canada has won the most titles with 27 championship wins.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first hockey world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcf966f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 is equal to 10. This is a basic arithmetic equation and the answer is a fundamental mathematical concept.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4e7651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: who won the first hockey world cup?\n",
      "AI:  The first hockey world cup was held in 1971 and was won by the Soviet Union. The Soviet Union won all five of the first hockey world cups, until the tournament was renamed to the Ice Hockey World Championships in 1993. Since then, Canada has won the most titles with 27 championship wins.\n",
      "Human: what is 5+5?\n",
      "AI:  5+5 is equal to 10. This is a basic arithmetic equation and the answer is a fundamental mathematical concept.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "859a7362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory=ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo=ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa091554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first hockey world cup was held in 1972 and was won by the Soviet Union. They defeated Czechoslovakia in the final and finished the tournament with a perfect record of six wins and no losses. The top scorer of the tournament was Anatoli Firsov from the Soviet Union, who scored 12 goals.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who won the first hockey world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ffea8247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  The answer to 5+5 is 10. Did you know that this is also known as the \"doubles\" fact in math, because both numbers are the same?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4207726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Soviet Union played against Czechoslovakia in the final of the first hockey world cup. They also played against Canada, Sweden, Finland, USA, and West Germany in the group stage.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who did soviet union play against?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
